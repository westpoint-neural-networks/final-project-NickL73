{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coachNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgZnSk7s4Cv1",
        "colab_type": "text"
      },
      "source": [
        "# Ahead of the Game: Coaching Predictability in NCAA Football\n",
        "\n",
        "This notebook is Part I in a series that seeks to model the predictability of offenseive playcallers in the NCAA FBS football league. While this idea could be practically applied to any offensive playcaller in the game, we will use Lincoln Riley, the head coach of the Oklahoma Sooners, as a singular case study.\n",
        "\n",
        "![](https://bloximages.newyork1.vip.townnews.com/oudaily.com/content/tncms/assets/v3/editorial/3/18/3188a808-1922-11ea-988f-473c9fa86f91/5debf40bd8b17.image.jpg?resize=400%2C267)\n",
        "\n",
        "Lincoln Riley is known for being an exceptionally talented playcaller, but is he as unpredicatable as analysts make him out to be? We will find out through the course of this notebook.\n",
        "\n",
        "**NOTE: This notebook is meant to be used in [Google Colaboratory](https://colab.research.google.com). The instructions will assume as much, and may not be accurate if you're using a different platform.**\n",
        "\n",
        "Ok, let's begin. Start by importing the required modules and setting a random seed. This random seed let's us have reproducible results. The seeding function has been buggy for me, so please excuse if the numbers and plots I describe don't match the outputs of all the cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D1D1RlKcG4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "import random\n",
        "\n",
        "seed(485)\n",
        "random.seed(485)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apZ5EmTBvCxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbkoSAwQ6Rwz",
        "colab_type": "text"
      },
      "source": [
        "## Preparing our Data\n",
        "\n",
        "The data we will be using was scraped from [collegefootballdata.com](https://www.collegefootballdata.com)\n",
        "\n",
        "Since we are using Lincoln Riley as our case study, it consists of (presumably) every play that Lincoln Riley called as either an offensive coordinator or head coach during his tenures at Eastern Carolina and Oklahoma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLfWrWmH6_bW",
        "colab_type": "text"
      },
      "source": [
        "First, import the data. To do this on Google Colab, you will first need to download the \"coachingData.csv\" from the models folder in the [GitHub repository](https://github.com/westpoint-neural-networks/final-project-NickL73). Next, you will need to click on the folder icon on the toolbar to the left of Google Colab and upload the dataset.\n",
        "\n",
        "Once you have done that, load it into a Pandas dataframe and we'll inspect the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15OBpS2NwChs",
        "colab_type": "code",
        "outputId": "b5e24315-b9d7-47ce-9331-824dc4e96cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df = pd.read_csv('/content/coachingData.csv')\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "      <th>play_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>1870</td>\n",
              "      <td>70</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3368</td>\n",
              "      <td>1568</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2470</td>\n",
              "      <td>670</td>\n",
              "      <td>90</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>2812</td>\n",
              "      <td>1012</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2258</td>\n",
              "      <td>458</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9506</th>\n",
              "      <td>27</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>1861</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9507</th>\n",
              "      <td>34</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>375</td>\n",
              "      <td>375</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9508</th>\n",
              "      <td>42</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>1563</td>\n",
              "      <td>1563</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9509</th>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3387</td>\n",
              "      <td>1587</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9510</th>\n",
              "      <td>14</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>3014</td>\n",
              "      <td>1214</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9511 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      score_differential  oneScoreGame  period  ...  down  distance  play_type\n",
              "0                      7          True       2  ...     1        10       Pass\n",
              "1                      0          True       1  ...     2         6       Pass\n",
              "2                      0          True       2  ...     1        10       Pass\n",
              "3                      8         False       1  ...     1        20       Pass\n",
              "4                     -8         False       2  ...     1        10       Pass\n",
              "...                  ...           ...     ...  ...   ...       ...        ...\n",
              "9506                  27         False       2  ...     1         1       Rush\n",
              "9507                  34         False       4  ...     3         1       Rush\n",
              "9508                  42         False       3  ...     2         1       Rush\n",
              "9509                   7          True       1  ...     3         1       Rush\n",
              "9510                  14         False       1  ...     1         1       Rush\n",
              "\n",
              "[9511 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jZfiNtx8DiS",
        "colab_type": "text"
      },
      "source": [
        "You'll notice that the data comes with some nice work already done to it. Before loading the CSV, we conducted some feature cleaning and feature engineering to get the best possible set of features for use in our network. In general, these features are derived from the information that could be found on a scoreboard. You'll notice our target feature, **play_type**, is the last column in the DataFrame. This will be the what we eventually try to predict.\n",
        "\n",
        "\n",
        "Now that we have our data in a Pandas data frame, we're going to start preparing it for use in a neural network. The first step we will take will be to formally define our target values (the play type) and input values (the scoreboard information) by [indexing](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) our dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahSpeEIvxjI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,0:8]\n",
        "y = df.iloc[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF-QHhq2DFvi",
        "colab_type": "text"
      },
      "source": [
        "### Vectorizing the Data\n",
        "\n",
        "For use in a neural network, each piece of data must be interpretable by a machine. This means things like our values of \"True\" and \"False\", as well as our target values of \"Rush\" and \"Pass\", must be converted into some number. To do this, we will simply binarize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXxUFb16DtPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.replace({True:1, False:0})\n",
        "y = y.replace({'Rush':0, 'Pass':1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9oiyZIgDwhv",
        "colab_type": "text"
      },
      "source": [
        "Additionally, since we want to predict a specific binary category of play_type, we will use the built-in Keras utility **to_categorical** to automatically create two seperate targets that the model can \"choose\" between when making predictions. We can see what this looks like be executing the next block of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FlStfi06Ksg",
        "colab_type": "code",
        "outputId": "0919730a-ea11-4a1a-be4d-ba739962db9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xuZOF039uxp",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the Data\n",
        "\n",
        "In order to use a loss function in training our model, we will need to split the data into a training set and a validation set. However, we only have one data set, so we will need to split it.\n",
        "\n",
        "Using the scikit-learn [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function, we will split our data into two. This function automatically shuffles our data, which helps us avoid training on only a range of years and validating on a different set of years. This will help increase the generality of our model.\n",
        "\n",
        "We will use 85% of the data in the training set, and the remaining 15% of the data in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLbGZQPyFg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUPAzJMtEsSh",
        "colab_type": "text"
      },
      "source": [
        "###Scaling and Normalizing the Data\n",
        "\n",
        "As you probably saw in the original DataFrame, each feature in our dataset has a significantly different range of values. This makes it hard for a neural network to properly make connections and relationships between values.\n",
        "\n",
        "To improve the accuracy of our model, we will need to scale and transform all of our data so that the mean centers on 0 and the minimum and maximum values of a feature are just one standard deviation away from the mean. This will put all of our values into a much more reasonable range, and each feature's range will be fairly similar.\n",
        "\n",
        "To do this, we will apply the sklearn [StandardScaler](https://stackoverflow.com/questions/38420847/apply-standardscaler-to-parts-of-a-data-set) to the features of our DataFrame that are not binary 1's or 0's. We will start by fitting the StandardScaler to our **training data only** and transforming all values in the **training data** to that scale. It's very important that we do not do this to the validation data at the same time, as that would cause data leakage in the model and decrease the overall accuracy of our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pya78CZJMBB0",
        "colab_type": "code",
        "outputId": "2afe3cae-3330-4372-b650-bd9dba18086e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "numeric = ['score_differential', 'period', 'seconds_remaining', 'secondsInHalf', 'yardsToGoal', 'down', 'distance']\n",
        "scaled_features = X_train.copy()\n",
        "features = scaled_features[numeric]\n",
        "scaler = ss.fit(features.values)\n",
        "features = ss.transform(features.values)\n",
        "\n",
        "scaled_features[numeric] = features\n",
        "\n",
        "X_train = scaled_features\n",
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3671</th>\n",
              "      <td>-0.010096</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.833389</td>\n",
              "      <td>0.008382</td>\n",
              "      <td>0.621726</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>-0.270233</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.654470</td>\n",
              "      <td>-0.337810</td>\n",
              "      <td>0.824789</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>1.951379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1627</th>\n",
              "      <td>-0.270233</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>1.529287</td>\n",
              "      <td>1.354886</td>\n",
              "      <td>-0.677882</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>-1.404828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8200</th>\n",
              "      <td>0.640246</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.082873</td>\n",
              "      <td>-1.443802</td>\n",
              "      <td>-0.596657</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1133</th>\n",
              "      <td>0.900383</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.313584</td>\n",
              "      <td>-0.997397</td>\n",
              "      <td>-0.068691</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>-0.270233</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.002831</td>\n",
              "      <td>-1.598677</td>\n",
              "      <td>-1.815039</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>-1.146658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1601</th>\n",
              "      <td>1.290588</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.057448</td>\n",
              "      <td>-1.492998</td>\n",
              "      <td>-0.515431</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-1.146658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>-0.465336</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>1.052799</td>\n",
              "      <td>0.432922</td>\n",
              "      <td>0.418662</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-0.630319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8600</th>\n",
              "      <td>0.054938</td>\n",
              "      <td>1</td>\n",
              "      <td>1.326604</td>\n",
              "      <td>-1.089514</td>\n",
              "      <td>-0.432557</td>\n",
              "      <td>-0.759108</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>-0.465336</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>1.178984</td>\n",
              "      <td>0.677078</td>\n",
              "      <td>1.068466</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-0.888489</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8084 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      score_differential  oneScoreGame  ...      down  distance\n",
              "3671           -0.010096             1  ...  1.543166  0.402360\n",
              "3119           -0.270233             1  ...  1.543166  1.951379\n",
              "1627           -0.270233             1  ...  1.543166 -1.404828\n",
              "8200            0.640246             0  ... -0.919077  0.402360\n",
              "1133            0.900383             0  ... -0.919077  0.402360\n",
              "...                  ...           ...  ...       ...       ...\n",
              "2414           -0.270233             1  ... -0.919077 -1.146658\n",
              "1601            1.290588             0  ...  0.312044 -1.146658\n",
              "174            -0.465336             1  ...  0.312044 -0.630319\n",
              "8600            0.054938             1  ... -0.919077  0.402360\n",
              "496            -0.465336             1  ...  0.312044 -0.888489\n",
              "\n",
              "[8084 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtpUw_1n5MFH",
        "colab_type": "text"
      },
      "source": [
        "As you can see, our data is completely unrecognizable. That's okay. Even if we can't make much sense of it, the computer understands it perfectly well.\n",
        "\n",
        "Now, we're ready to scale the validation data. One nice thing about using the sklearn StandardScaler is that it saves the the mean and standard deviations from the last time it was fit. This means that we can transform future data on the same scale used to transform the training data.\n",
        "\n",
        "That's exactly what we're going to do with the validation data. At this point, it's very important that we do not instantiate a new StandardScaler nor fit existing StandardScaler to the validation data. We just want to use that scale to transform the validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIWYwqve5Loh",
        "colab_type": "code",
        "outputId": "f1dd5019-e6fc-40e5-95a8-d32efc24086a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "scaled_features = X_validation.copy()\n",
        "features = scaled_features[numeric]\n",
        "features = ss.transform(features.values)\n",
        "\n",
        "scaled_features[numeric] = features\n",
        "\n",
        "X_validation = scaled_features\n",
        "X_validation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4750</th>\n",
              "      <td>2.461204</td>\n",
              "      <td>0</td>\n",
              "      <td>0.444819</td>\n",
              "      <td>-0.341823</td>\n",
              "      <td>1.014160</td>\n",
              "      <td>0.784177</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6349</th>\n",
              "      <td>1.160520</td>\n",
              "      <td>0</td>\n",
              "      <td>1.326604</td>\n",
              "      <td>-1.395558</td>\n",
              "      <td>-1.024728</td>\n",
              "      <td>-0.109304</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4012</th>\n",
              "      <td>-1.440849</td>\n",
              "      <td>0</td>\n",
              "      <td>0.444819</td>\n",
              "      <td>-0.384198</td>\n",
              "      <td>0.932167</td>\n",
              "      <td>-1.855652</td>\n",
              "      <td>2.774287</td>\n",
              "      <td>-1.921168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3070</th>\n",
              "      <td>0.640246</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.258966</td>\n",
              "      <td>-1.103076</td>\n",
              "      <td>1.068466</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8053</th>\n",
              "      <td>-0.660438</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.268383</td>\n",
              "      <td>-1.084856</td>\n",
              "      <td>0.743564</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-1.404828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6241</th>\n",
              "      <td>0.445143</td>\n",
              "      <td>0</td>\n",
              "      <td>0.444819</td>\n",
              "      <td>-0.127121</td>\n",
              "      <td>1.429590</td>\n",
              "      <td>0.540500</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-1.146658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3675</th>\n",
              "      <td>-1.180712</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>0.993474</td>\n",
              "      <td>0.318132</td>\n",
              "      <td>0.621726</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>-0.113979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7106</th>\n",
              "      <td>-0.270233</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>1.489737</td>\n",
              "      <td>1.278359</td>\n",
              "      <td>-1.936877</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>-1.921168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8699</th>\n",
              "      <td>-2.286294</td>\n",
              "      <td>0</td>\n",
              "      <td>1.326604</td>\n",
              "      <td>-1.146956</td>\n",
              "      <td>-0.543703</td>\n",
              "      <td>2.002559</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2668</th>\n",
              "      <td>0.250041</td>\n",
              "      <td>0</td>\n",
              "      <td>0.444819</td>\n",
              "      <td>-0.779702</td>\n",
              "      <td>0.166901</td>\n",
              "      <td>0.215598</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>0.144191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1427 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      score_differential  oneScoreGame  ...      down  distance\n",
              "4750            2.461204             0  ... -0.919077  0.402360\n",
              "6349            1.160520             0  ... -0.919077  0.402360\n",
              "4012           -1.440849             0  ...  2.774287 -1.921168\n",
              "3070            0.640246             0  ... -0.919077  0.402360\n",
              "8053           -0.660438             1  ...  0.312044 -1.404828\n",
              "...                  ...           ...  ...       ...       ...\n",
              "6241            0.445143             0  ...  0.312044 -1.146658\n",
              "3675           -1.180712             0  ...  1.543166 -0.113979\n",
              "7106           -0.270233             1  ... -0.919077 -1.921168\n",
              "8699           -2.286294             0  ...  0.312044  0.402360\n",
              "2668            0.250041             0  ...  0.312044  0.144191\n",
              "\n",
              "[1427 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaRr5_27H3TS",
        "colab_type": "text"
      },
      "source": [
        "Perfect. Now that all of our data has been vectorized, scaled, and transformed, we're ready to start building our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uDE7_YoIAIp",
        "colab_type": "text"
      },
      "source": [
        "##Building a Model\n",
        "\n",
        "We're going to use Keras to create a densely connected network for this binary classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGqvc0JrJKqv",
        "colab_type": "text"
      },
      "source": [
        "The number of layers, hidden units, and amount of dropout all came from a large amount of manual tuning to produce a low level of  validation loss and high validation accuracy.\n",
        "\n",
        "In this model, our densely connected layers use the **elu** activation function. This came as the result of many trials using **relu** and **tanh** and discovering that **elu** resulted in much better results.\n",
        "\n",
        "In our final layer, we use a **sigmoid** activation function to give us a probability distribution between our two possible target values (rush or pass). This is standard practice in binary classification tasks, as well as the use of **binary crossentropy** as a loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IuJWx7x00fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models, layers, optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(8,activation='elu', input_dim=8))\n",
        "model.add(layers.Dense(8,activation='elu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6zcWjzjKExn",
        "colab_type": "text"
      },
      "source": [
        "With our sequential model built and compiled, we're ready to begin training. We'll train for 150 epochs for this model. Through testing, we found 150 epoch to be a good number that prevented too much overfitting.\n",
        "\n",
        "Okay, let's train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0_trt8e1OgC",
        "colab_type": "code",
        "outputId": "16933647-1080-4927-8823-6c20f0b26fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history2 = model.fit(X_train, y_train,batch_size=24, epochs=150, validation_data=(X_validation, y_validation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.7333 - accuracy: 0.5285 - val_loss: 0.6837 - val_accuracy: 0.5543\n",
            "Epoch 2/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5760 - val_loss: 0.6763 - val_accuracy: 0.5781\n",
            "Epoch 3/150\n",
            "337/337 [==============================] - 1s 1ms/step - loss: 0.6768 - accuracy: 0.5860 - val_loss: 0.6733 - val_accuracy: 0.5788\n",
            "Epoch 4/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6711 - accuracy: 0.5936 - val_loss: 0.6720 - val_accuracy: 0.5795\n",
            "Epoch 5/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6675 - accuracy: 0.5962 - val_loss: 0.6703 - val_accuracy: 0.5781\n",
            "Epoch 6/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.5977 - val_loss: 0.6706 - val_accuracy: 0.5851\n",
            "Epoch 7/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.5997 - val_loss: 0.6707 - val_accuracy: 0.5893\n",
            "Epoch 8/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.6001 - val_loss: 0.6684 - val_accuracy: 0.5950\n",
            "Epoch 9/150\n",
            "337/337 [==============================] - 1s 1ms/step - loss: 0.6626 - accuracy: 0.6075 - val_loss: 0.6674 - val_accuracy: 0.5872\n",
            "Epoch 10/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6631 - accuracy: 0.6081 - val_loss: 0.6652 - val_accuracy: 0.5964\n",
            "Epoch 11/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6084 - val_loss: 0.6654 - val_accuracy: 0.5929\n",
            "Epoch 12/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6065 - val_loss: 0.6639 - val_accuracy: 0.5943\n",
            "Epoch 13/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.6082 - val_loss: 0.6632 - val_accuracy: 0.5971\n",
            "Epoch 14/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6042 - val_loss: 0.6618 - val_accuracy: 0.6006\n",
            "Epoch 15/150\n",
            "337/337 [==============================] - 1s 1ms/step - loss: 0.6590 - accuracy: 0.6117 - val_loss: 0.6599 - val_accuracy: 0.6062\n",
            "Epoch 16/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6585 - accuracy: 0.6075 - val_loss: 0.6589 - val_accuracy: 0.6076\n",
            "Epoch 17/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6091 - val_loss: 0.6583 - val_accuracy: 0.6118\n",
            "Epoch 18/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6145 - val_loss: 0.6551 - val_accuracy: 0.6237\n",
            "Epoch 19/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6117 - val_loss: 0.6560 - val_accuracy: 0.6083\n",
            "Epoch 20/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6152 - val_loss: 0.6533 - val_accuracy: 0.6174\n",
            "Epoch 21/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6154 - val_loss: 0.6515 - val_accuracy: 0.6272\n",
            "Epoch 22/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6080 - val_loss: 0.6514 - val_accuracy: 0.6153\n",
            "Epoch 23/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6525 - accuracy: 0.6247 - val_loss: 0.6501 - val_accuracy: 0.6209\n",
            "Epoch 24/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6502 - accuracy: 0.6225 - val_loss: 0.6519 - val_accuracy: 0.6167\n",
            "Epoch 25/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6521 - accuracy: 0.6169 - val_loss: 0.6530 - val_accuracy: 0.6118\n",
            "Epoch 26/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6519 - accuracy: 0.6164 - val_loss: 0.6512 - val_accuracy: 0.6181\n",
            "Epoch 27/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6486 - accuracy: 0.6218 - val_loss: 0.6514 - val_accuracy: 0.6041\n",
            "Epoch 28/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6508 - accuracy: 0.6194 - val_loss: 0.6490 - val_accuracy: 0.6286\n",
            "Epoch 29/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6223 - val_loss: 0.6484 - val_accuracy: 0.6244\n",
            "Epoch 30/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6495 - accuracy: 0.6259 - val_loss: 0.6486 - val_accuracy: 0.6230\n",
            "Epoch 31/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6474 - accuracy: 0.6253 - val_loss: 0.6487 - val_accuracy: 0.6230\n",
            "Epoch 32/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6491 - accuracy: 0.6217 - val_loss: 0.6494 - val_accuracy: 0.6237\n",
            "Epoch 33/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6477 - accuracy: 0.6214 - val_loss: 0.6477 - val_accuracy: 0.6230\n",
            "Epoch 34/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6512 - accuracy: 0.6210 - val_loss: 0.6474 - val_accuracy: 0.6244\n",
            "Epoch 35/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6485 - accuracy: 0.6291 - val_loss: 0.6484 - val_accuracy: 0.6216\n",
            "Epoch 36/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6491 - accuracy: 0.6204 - val_loss: 0.6482 - val_accuracy: 0.6195\n",
            "Epoch 37/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6464 - accuracy: 0.6256 - val_loss: 0.6491 - val_accuracy: 0.6195\n",
            "Epoch 38/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6483 - accuracy: 0.6230 - val_loss: 0.6471 - val_accuracy: 0.6244\n",
            "Epoch 39/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6488 - accuracy: 0.6201 - val_loss: 0.6497 - val_accuracy: 0.6125\n",
            "Epoch 40/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6475 - accuracy: 0.6244 - val_loss: 0.6468 - val_accuracy: 0.6202\n",
            "Epoch 41/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6466 - accuracy: 0.6223 - val_loss: 0.6493 - val_accuracy: 0.6097\n",
            "Epoch 42/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6469 - accuracy: 0.6237 - val_loss: 0.6474 - val_accuracy: 0.6216\n",
            "Epoch 43/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6454 - accuracy: 0.6264 - val_loss: 0.6468 - val_accuracy: 0.6181\n",
            "Epoch 44/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6461 - accuracy: 0.6249 - val_loss: 0.6467 - val_accuracy: 0.6237\n",
            "Epoch 45/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6466 - accuracy: 0.6248 - val_loss: 0.6486 - val_accuracy: 0.6076\n",
            "Epoch 46/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6452 - accuracy: 0.6228 - val_loss: 0.6478 - val_accuracy: 0.6181\n",
            "Epoch 47/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6478 - accuracy: 0.6232 - val_loss: 0.6480 - val_accuracy: 0.6146\n",
            "Epoch 48/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6470 - accuracy: 0.6254 - val_loss: 0.6506 - val_accuracy: 0.6062\n",
            "Epoch 49/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6476 - accuracy: 0.6220 - val_loss: 0.6470 - val_accuracy: 0.6111\n",
            "Epoch 50/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6444 - accuracy: 0.6252 - val_loss: 0.6477 - val_accuracy: 0.6167\n",
            "Epoch 51/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6267 - val_loss: 0.6472 - val_accuracy: 0.6097\n",
            "Epoch 52/150\n",
            "337/337 [==============================] - 1s 1ms/step - loss: 0.6455 - accuracy: 0.6242 - val_loss: 0.6491 - val_accuracy: 0.6062\n",
            "Epoch 53/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6471 - accuracy: 0.6284 - val_loss: 0.6481 - val_accuracy: 0.6069\n",
            "Epoch 54/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6450 - accuracy: 0.6252 - val_loss: 0.6455 - val_accuracy: 0.6265\n",
            "Epoch 55/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.6226 - val_loss: 0.6451 - val_accuracy: 0.6293\n",
            "Epoch 56/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6460 - accuracy: 0.6264 - val_loss: 0.6468 - val_accuracy: 0.6153\n",
            "Epoch 57/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6457 - accuracy: 0.6277 - val_loss: 0.6454 - val_accuracy: 0.6258\n",
            "Epoch 58/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6459 - accuracy: 0.6237 - val_loss: 0.6456 - val_accuracy: 0.6300\n",
            "Epoch 59/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6436 - accuracy: 0.6264 - val_loss: 0.6462 - val_accuracy: 0.6237\n",
            "Epoch 60/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6440 - accuracy: 0.6215 - val_loss: 0.6469 - val_accuracy: 0.6076\n",
            "Epoch 61/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6446 - accuracy: 0.6174 - val_loss: 0.6467 - val_accuracy: 0.6153\n",
            "Epoch 62/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6293 - val_loss: 0.6459 - val_accuracy: 0.6139\n",
            "Epoch 63/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6459 - accuracy: 0.6253 - val_loss: 0.6456 - val_accuracy: 0.6167\n",
            "Epoch 64/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6449 - accuracy: 0.6225 - val_loss: 0.6457 - val_accuracy: 0.6251\n",
            "Epoch 65/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6441 - accuracy: 0.6308 - val_loss: 0.6450 - val_accuracy: 0.6300\n",
            "Epoch 66/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6440 - accuracy: 0.6215 - val_loss: 0.6452 - val_accuracy: 0.6258\n",
            "Epoch 67/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6440 - accuracy: 0.6296 - val_loss: 0.6485 - val_accuracy: 0.6069\n",
            "Epoch 68/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6432 - accuracy: 0.6275 - val_loss: 0.6460 - val_accuracy: 0.6216\n",
            "Epoch 69/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6430 - accuracy: 0.6272 - val_loss: 0.6453 - val_accuracy: 0.6279\n",
            "Epoch 70/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.6265 - val_loss: 0.6458 - val_accuracy: 0.6251\n",
            "Epoch 71/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6226 - val_loss: 0.6447 - val_accuracy: 0.6237\n",
            "Epoch 72/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.6236 - val_loss: 0.6455 - val_accuracy: 0.6160\n",
            "Epoch 73/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6437 - accuracy: 0.6236 - val_loss: 0.6450 - val_accuracy: 0.6314\n",
            "Epoch 74/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6421 - accuracy: 0.6273 - val_loss: 0.6464 - val_accuracy: 0.6118\n",
            "Epoch 75/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6418 - accuracy: 0.6215 - val_loss: 0.6465 - val_accuracy: 0.6230\n",
            "Epoch 76/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6447 - accuracy: 0.6247 - val_loss: 0.6441 - val_accuracy: 0.6314\n",
            "Epoch 77/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6448 - accuracy: 0.6305 - val_loss: 0.6456 - val_accuracy: 0.6230\n",
            "Epoch 78/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6231 - val_loss: 0.6439 - val_accuracy: 0.6314\n",
            "Epoch 79/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6427 - accuracy: 0.6270 - val_loss: 0.6443 - val_accuracy: 0.6244\n",
            "Epoch 80/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6440 - accuracy: 0.6220 - val_loss: 0.6451 - val_accuracy: 0.6251\n",
            "Epoch 81/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6442 - accuracy: 0.6257 - val_loss: 0.6479 - val_accuracy: 0.6090\n",
            "Epoch 82/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6441 - accuracy: 0.6223 - val_loss: 0.6466 - val_accuracy: 0.6132\n",
            "Epoch 83/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6450 - accuracy: 0.6296 - val_loss: 0.6459 - val_accuracy: 0.6174\n",
            "Epoch 84/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6438 - accuracy: 0.6275 - val_loss: 0.6456 - val_accuracy: 0.6104\n",
            "Epoch 85/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6446 - accuracy: 0.6262 - val_loss: 0.6448 - val_accuracy: 0.6244\n",
            "Epoch 86/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6443 - accuracy: 0.6300 - val_loss: 0.6475 - val_accuracy: 0.6097\n",
            "Epoch 87/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6431 - accuracy: 0.6286 - val_loss: 0.6477 - val_accuracy: 0.6167\n",
            "Epoch 88/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6430 - accuracy: 0.6293 - val_loss: 0.6435 - val_accuracy: 0.6272\n",
            "Epoch 89/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6405 - accuracy: 0.6326 - val_loss: 0.6467 - val_accuracy: 0.6111\n",
            "Epoch 90/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6412 - accuracy: 0.6238 - val_loss: 0.6443 - val_accuracy: 0.6230\n",
            "Epoch 91/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6417 - accuracy: 0.6218 - val_loss: 0.6442 - val_accuracy: 0.6265\n",
            "Epoch 92/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.6280 - val_loss: 0.6432 - val_accuracy: 0.6342\n",
            "Epoch 93/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6414 - accuracy: 0.6335 - val_loss: 0.6435 - val_accuracy: 0.6244\n",
            "Epoch 94/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6405 - accuracy: 0.6280 - val_loss: 0.6451 - val_accuracy: 0.6209\n",
            "Epoch 95/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6461 - accuracy: 0.6231 - val_loss: 0.6440 - val_accuracy: 0.6342\n",
            "Epoch 96/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6420 - accuracy: 0.6262 - val_loss: 0.6431 - val_accuracy: 0.6293\n",
            "Epoch 97/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6415 - accuracy: 0.6301 - val_loss: 0.6472 - val_accuracy: 0.6097\n",
            "Epoch 98/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6423 - accuracy: 0.6278 - val_loss: 0.6450 - val_accuracy: 0.6139\n",
            "Epoch 99/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6419 - accuracy: 0.6324 - val_loss: 0.6521 - val_accuracy: 0.6020\n",
            "Epoch 100/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6432 - accuracy: 0.6263 - val_loss: 0.6448 - val_accuracy: 0.6258\n",
            "Epoch 101/150\n",
            "337/337 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6249 - val_loss: 0.6447 - val_accuracy: 0.6139\n",
            "Epoch 102/150\n",
            "337/337 [==============================] - 1s 1ms/step - loss: 0.6434 - accuracy: 0.6298 - val_loss: 0.6442 - val_accuracy: 0.6174\n",
            "Epoch 103/150\n",
            "337/337 [==============================] - 1s 1ms/step - loss: 0.6419 - accuracy: 0.6225 - val_loss: 0.6462 - val_accuracy: 0.6076\n",
            "Epoch 104/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6288 - val_loss: 0.6471 - val_accuracy: 0.6104\n",
            "Epoch 105/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6435 - accuracy: 0.6301 - val_loss: 0.6442 - val_accuracy: 0.6349\n",
            "Epoch 106/150\n",
            "337/337 [==============================] - 1s 1ms/step - loss: 0.6402 - accuracy: 0.6264 - val_loss: 0.6449 - val_accuracy: 0.6223\n",
            "Epoch 107/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.6270 - val_loss: 0.6438 - val_accuracy: 0.6300\n",
            "Epoch 108/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6223 - val_loss: 0.6436 - val_accuracy: 0.6307\n",
            "Epoch 109/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6431 - accuracy: 0.6265 - val_loss: 0.6453 - val_accuracy: 0.6244\n",
            "Epoch 110/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6416 - accuracy: 0.6274 - val_loss: 0.6440 - val_accuracy: 0.6307\n",
            "Epoch 111/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6415 - accuracy: 0.6310 - val_loss: 0.6439 - val_accuracy: 0.6237\n",
            "Epoch 112/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6440 - accuracy: 0.6327 - val_loss: 0.6435 - val_accuracy: 0.6293\n",
            "Epoch 113/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6409 - accuracy: 0.6253 - val_loss: 0.6438 - val_accuracy: 0.6265\n",
            "Epoch 114/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6409 - accuracy: 0.6280 - val_loss: 0.6439 - val_accuracy: 0.6307\n",
            "Epoch 115/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6422 - accuracy: 0.6298 - val_loss: 0.6435 - val_accuracy: 0.6223\n",
            "Epoch 116/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6418 - accuracy: 0.6233 - val_loss: 0.6440 - val_accuracy: 0.6300\n",
            "Epoch 117/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.6278 - val_loss: 0.6423 - val_accuracy: 0.6321\n",
            "Epoch 118/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6426 - accuracy: 0.6314 - val_loss: 0.6440 - val_accuracy: 0.6286\n",
            "Epoch 119/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6432 - accuracy: 0.6293 - val_loss: 0.6440 - val_accuracy: 0.6265\n",
            "Epoch 120/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6316 - val_loss: 0.6434 - val_accuracy: 0.6307\n",
            "Epoch 121/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6410 - accuracy: 0.6355 - val_loss: 0.6499 - val_accuracy: 0.6076\n",
            "Epoch 122/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6400 - accuracy: 0.6262 - val_loss: 0.6454 - val_accuracy: 0.6139\n",
            "Epoch 123/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6300 - val_loss: 0.6441 - val_accuracy: 0.6160\n",
            "Epoch 124/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6419 - accuracy: 0.6257 - val_loss: 0.6461 - val_accuracy: 0.6125\n",
            "Epoch 125/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6407 - accuracy: 0.6232 - val_loss: 0.6439 - val_accuracy: 0.6230\n",
            "Epoch 126/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6397 - accuracy: 0.6267 - val_loss: 0.6450 - val_accuracy: 0.6223\n",
            "Epoch 127/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6426 - accuracy: 0.6342 - val_loss: 0.6428 - val_accuracy: 0.6293\n",
            "Epoch 128/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6415 - accuracy: 0.6312 - val_loss: 0.6421 - val_accuracy: 0.6314\n",
            "Epoch 129/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6416 - accuracy: 0.6332 - val_loss: 0.6425 - val_accuracy: 0.6363\n",
            "Epoch 130/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6422 - accuracy: 0.6246 - val_loss: 0.6427 - val_accuracy: 0.6265\n",
            "Epoch 131/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6394 - accuracy: 0.6282 - val_loss: 0.6429 - val_accuracy: 0.6314\n",
            "Epoch 132/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6419 - accuracy: 0.6218 - val_loss: 0.6442 - val_accuracy: 0.6314\n",
            "Epoch 133/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6422 - accuracy: 0.6277 - val_loss: 0.6462 - val_accuracy: 0.6132\n",
            "Epoch 134/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6412 - accuracy: 0.6327 - val_loss: 0.6477 - val_accuracy: 0.6111\n",
            "Epoch 135/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6430 - accuracy: 0.6272 - val_loss: 0.6433 - val_accuracy: 0.6370\n",
            "Epoch 136/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6426 - accuracy: 0.6256 - val_loss: 0.6414 - val_accuracy: 0.6349\n",
            "Epoch 137/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6400 - accuracy: 0.6308 - val_loss: 0.6428 - val_accuracy: 0.6293\n",
            "Epoch 138/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6403 - accuracy: 0.6312 - val_loss: 0.6475 - val_accuracy: 0.6083\n",
            "Epoch 139/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6422 - accuracy: 0.6294 - val_loss: 0.6418 - val_accuracy: 0.6384\n",
            "Epoch 140/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6433 - accuracy: 0.6244 - val_loss: 0.6422 - val_accuracy: 0.6342\n",
            "Epoch 141/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.6311 - val_loss: 0.6428 - val_accuracy: 0.6265\n",
            "Epoch 142/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6418 - accuracy: 0.6279 - val_loss: 0.6444 - val_accuracy: 0.6181\n",
            "Epoch 143/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6392 - accuracy: 0.6301 - val_loss: 0.6431 - val_accuracy: 0.6258\n",
            "Epoch 144/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6401 - accuracy: 0.6308 - val_loss: 0.6437 - val_accuracy: 0.6286\n",
            "Epoch 145/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6399 - accuracy: 0.6348 - val_loss: 0.6435 - val_accuracy: 0.6321\n",
            "Epoch 146/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6418 - accuracy: 0.6317 - val_loss: 0.6432 - val_accuracy: 0.6272\n",
            "Epoch 147/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6424 - accuracy: 0.6277 - val_loss: 0.6421 - val_accuracy: 0.6265\n",
            "Epoch 148/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6423 - accuracy: 0.6284 - val_loss: 0.6426 - val_accuracy: 0.6265\n",
            "Epoch 149/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6416 - accuracy: 0.6296 - val_loss: 0.6469 - val_accuracy: 0.6118\n",
            "Epoch 150/150\n",
            "337/337 [==============================] - 1s 2ms/step - loss: 0.6400 - accuracy: 0.6243 - val_loss: 0.6427 - val_accuracy: 0.6265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiGIz1r9Ke4w",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the model's performance in terms of accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Luk9tRA1jHU",
        "colab_type": "code",
        "outputId": "4185aca1-b86e-453f-c5c4-8d042b9117d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history2.history['accuracy'])\n",
        "plt.plot(history2.history['val_accuracy'])\n",
        "plt.title('Training v. Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKrA5EE0KmzR",
        "colab_type": "text"
      },
      "source": [
        "Okay, this is actually pretty decent. The validation and training accuracies track each other fairly well and we don't see much evidence of overfitting or underfitting. With a final validation accuracy of 62.65%, let's take a look at the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFSt2bSO1pDB",
        "colab_type": "code",
        "outputId": "7bbf2d9e-5264-4896-ec79-77f33a69179d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('Training v. Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCXl2Vu7LE13",
        "colab_type": "text"
      },
      "source": [
        "Like we saw in the accuracy, we see a close tracking between the training and validation losses. This model looks to be about as good as it will get, so let's save it and test it out.\n",
        "\n",
        "**NOTE: The next block of code will save the model to the same content folder as our dataset in the Colab runtime. If you want to keep the model, be sure to right click and download it from the Colab directory.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCjp34OeRYwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('coachingModel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q15570-Lz79",
        "colab_type": "text"
      },
      "source": [
        "##Testing the Model\n",
        "\n",
        "To test how good our model is on unseen data, we will use it to try to predict every play in the 2019 Big XII Championship Game between Oklahoma and Baylor. Since our model did not train or validate on any play from this game, it should be a good test of how well our model generalizes on new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4ESYOD8MdNZ",
        "colab_type": "text"
      },
      "source": [
        "To begin, we have to go through the same process of uploading the test dataset to Colab, setting our target values, and vectorizing and transforming the data for use in a neural network.\n",
        "\n",
        "Again, we must be careful to only transform the test set to the scale saved in the StandardScaler, which was fit on the test data at the beginning of the notebook. This is important in the test set because in a real-life scenario, the only context for scale we would have as plays occur would be every play that's previously occured."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Z6fHPXzdGe",
        "colab_type": "code",
        "outputId": "20aba60f-bef3-4528-e575-855e0f9015dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "testDF = pd.read_csv('/content/test.csv')\n",
        "XGame = testDF.iloc[:,0:8]\n",
        "yGame= testDF.iloc[:,8]\n",
        "\n",
        "XGame = XGame.replace({True:1, False:0})\n",
        "yGame = yGame.replace({'Rush':0, 'Pass':1})\n",
        "yGame = to_categorical(yGame)\n",
        "\n",
        "scaled_features = XGame.copy()\n",
        "features = scaled_features[numeric]\n",
        "features = ss.transform(features.values)\n",
        "\n",
        "scaled_features[numeric] = features\n",
        "\n",
        "XGame = scaled_features\n",
        "XGame"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.185006</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>1.151675</td>\n",
              "      <td>0.624239</td>\n",
              "      <td>-1.205848</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.380109</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.682721</td>\n",
              "      <td>-0.283148</td>\n",
              "      <td>0.906015</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.185006</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.340892</td>\n",
              "      <td>-0.944557</td>\n",
              "      <td>0.499887</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>1.176870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.270233</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.069689</td>\n",
              "      <td>-1.469311</td>\n",
              "      <td>1.515206</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>0.144191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.185006</td>\n",
              "      <td>1</td>\n",
              "      <td>1.326604</td>\n",
              "      <td>-1.111172</td>\n",
              "      <td>-0.474465</td>\n",
              "      <td>-1.693201</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>-0.372149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0.185006</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>1.371086</td>\n",
              "      <td>1.048779</td>\n",
              "      <td>-1.733814</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-0.630319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.185006</td>\n",
              "      <td>1</td>\n",
              "      <td>2.208388</td>\n",
              "      <td>-2.556645</td>\n",
              "      <td>-3.271331</td>\n",
              "      <td>-1.774426</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-1.146658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.185006</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.318750</td>\n",
              "      <td>1.144142</td>\n",
              "      <td>0.609662</td>\n",
              "      <td>-1.205848</td>\n",
              "      <td>1.543166</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.380109</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.649762</td>\n",
              "      <td>-0.346921</td>\n",
              "      <td>0.459275</td>\n",
              "      <td>-0.919077</td>\n",
              "      <td>0.402360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>-0.270233</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.436965</td>\n",
              "      <td>0.111123</td>\n",
              "      <td>-1.389140</td>\n",
              "      <td>1.230917</td>\n",
              "      <td>0.312044</td>\n",
              "      <td>-1.662998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    score_differential  oneScoreGame    period  ...  yardsToGoal      down  distance\n",
              "0             0.185006             1 -1.318750  ...    -1.205848  0.312044  0.402360\n",
              "1             0.380109             0 -0.436965  ...     0.906015 -0.919077  0.402360\n",
              "2             0.185006             1 -0.436965  ...     0.499887  1.543166  1.176870\n",
              "3            -0.270233             1 -0.436965  ...     1.515206  1.543166  0.144191\n",
              "4             0.185006             1  1.326604  ...    -1.693201  1.543166 -0.372149\n",
              "..                 ...           ...       ...  ...          ...       ...       ...\n",
              "69            0.185006             1 -1.318750  ...    -1.733814  0.312044 -0.630319\n",
              "70            0.185006             1  2.208388  ...    -1.774426  0.312044 -1.146658\n",
              "71            0.185006             1 -1.318750  ...    -1.205848  1.543166  0.402360\n",
              "72            0.380109             0 -0.436965  ...     0.459275 -0.919077  0.402360\n",
              "73           -0.270233             1 -0.436965  ...     1.230917  0.312044 -1.662998\n",
              "\n",
              "[74 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQZ6vEmeNDkT",
        "colab_type": "text"
      },
      "source": [
        "Looks good. Now let's use our model to evaluate the game and see how well we do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbnP9rN7MzXp",
        "colab_type": "text"
      },
      "source": [
        "###Model Performance\n",
        "\n",
        "With our test data all set up for input into our model, we are ready to test it out. We can use the Keras **evaluate** model function to get predictions for every play in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a870aff0-019c-408c-a78b-4cde88f229cc",
        "id": "SZTrB8kI_z51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model.evaluate(XGame, yGame)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.5946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6990373134613037, 0.5945945978164673]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnJcev75ObVu",
        "colab_type": "text"
      },
      "source": [
        "In this test set we only get about a 59.45% accuracy, even though we had a 62.65% final validation accuracy.  This 3% difference may seem significant, and it surely is, but our test set only had 74 plays in it. As such, in the context of this test set, we only got about two more predictions incorrect than our validation set would have us believe we are capable of.\n",
        "\n",
        "Let's take a closer look using the sklearn **classification report** which has several parameters beyond just accuracy which may help us better understand the behaviour of our model:\n",
        "\n",
        "\n",
        "*   *Precision* - The ratio of true positives to true positives plus false positives. In other words, the percentage of predictions that were correct for a given class.\n",
        "*   *Recall* - The ratio of true positives to true positives plus false positives. In other words, the percentage of instances of a certain class that were correctly identified.\n",
        "*   *f1-score* - The harmonic mean between precision and recall. Typically, this value is a bit more informative than just plain accuracy.\n",
        "* *support* - The number insances of a certain class in the test set.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ZuI8twA2VA",
        "colab_type": "code",
        "outputId": "b24cc047-6b2d-430a-c244-b39fb70e66cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "Y_test = np.argmax(yGame, axis=1) # Convert one-hot to index\n",
        "y_pred = model.predict_classes(XGame)\n",
        "print(classification_report(Y_test, y_pred, target_names=['Rush', 'Pass'], digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-2fc6320c7a16>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Rush     0.7576    0.5319    0.6250        47\n",
            "        Pass     0.4634    0.7037    0.5588        27\n",
            "\n",
            "    accuracy                         0.5946        74\n",
            "   macro avg     0.6105    0.6178    0.5919        74\n",
            "weighted avg     0.6502    0.5946    0.6009        74\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPnHs82Wi1zy",
        "colab_type": "text"
      },
      "source": [
        "Reading this chart, we are able to deduce that our model guesses \"Pass\" more often than \"Rush'. Since Pass has low precision, and high recall, we must be guessing pass a lot. \n",
        "\n",
        "In the context of football, this is probably a good thing- to over guess on pass, instead of rush. Pass plays potentially result in large gains and scoring opportunities. If we predict pass plays more often, we would position our defense in such a way to prevent these big plays from happening too often."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlp-YyVAuVEf",
        "colab_type": "text"
      },
      "source": [
        "##Conclusion\n",
        "\n",
        "This notebook explored whether or not we could evaluate the predictability of Lincoln Riley using data derived from the information available on the scoreboard.\n",
        "\n",
        "Ultimately, we were able to produce a model that achieved around 60% accuracy on a single test game. This may not seem that high, but we must remember that in the context of football, it pays to be unpredictable. If a coach were predictable, they surely would not have the same success that Lincoln Riley has experienced.\n",
        "\n",
        "We can get better, though. I'm sure of it. Let's see if we can use the Big XII Conference to predict Lincoln Riley's play-calling behavior. Perhaps he simply calls plays in the way that all of the coaches in the Big XII do. We will explore this idea in Part II of this series, [building a conference model](https://colab.research.google.com/drive/19qggMX5b_FWNvDxkJsxlwpzjAHW4fKl2#offline=true&sandboxMode=true).\n",
        "\n"
      ]
    }
  ]
}