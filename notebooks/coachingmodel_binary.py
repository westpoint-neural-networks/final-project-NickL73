# -*- coding: utf-8 -*-
"""coachingModel_binary.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ITENEu7jQ-3Hox3Mxr-TRgueKHElmwCH
"""

from numpy.random import seed
import random

seed(485)
random.seed(485)

import pandas as pd
import numpy as np
import tensorflow

df = pd.read_csv('/content/LincolnBinary2.csv')
df

"""https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html

https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
"""

from sklearn.model_selection import train_test_split

X = df.iloc[:,1:9]
y = df.iloc[:,10]

X = X.replace({True:1, False:0})
X

from keras.utils import to_categorical
y = y.replace({'Rush':0, 'Pass':1, 'FG':2, 'Punt':3})
y = to_categorical(y)
y

X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.15)

"""https://stackoverflow.com/questions/38420847/apply-standardscaler-to-parts-of-a-data-set"""

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
numeric = ['score_differential', 'period', 'seconds_remaining', 'secondsInHalf', 'yardsToGoal', 'down', 'distance']
scaled_features = X_train.copy()
features = scaled_features[numeric]
scaler = ss.fit(features.values)
features = ss.transform(features.values)

scaled_features[numeric] = features

X_train = scaled_features
X_train

"""Repeat for the validation data."""

#ss = StandardScaler()
#numeric = ['score_differential', 'period', 'seconds_remaining','secondsInHalf', 'yard50', 'yardsToGoal', 'down', 'distance', 'yards_gained']

scaled_features = X_validation.copy()
features = scaled_features[numeric]
#scaler = ss.fit(features.values)
features = ss.transform(features.values)

scaled_features[numeric] = features

X_validation = scaled_features
X_validation

from tensorflow.keras import models, layers, optimizers

model = models.Sequential()
model.add(layers.Dense(8,activation='elu', input_dim=8))
model.add(layers.Dense(8,activation='elu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(2, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history2 = model.fit(X_train, y_train,batch_size=24, epochs=150, validation_data=(X_validation, y_validation))

import matplotlib.pyplot as plt

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Training v. Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Training v. Validation Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

model.save('coachingModel.h5')

testDF = pd.read_csv('/content/testBinary2.csv')
XGame = testDF.iloc[:,1:9]
yGame= testDF.iloc[:,10]

XGame

XGame = XGame.replace({True:1, False:0})
yGame = yGame.replace({'Rush':0, 'Pass':1, 'FG':2, 'Punt':3})
yGame = to_categorical(yGame)

#numeric = ['score_differential', 'period', 'seconds_remaining', 'secondsInHalf', 'yard50', 'yardsToGoal', 'down', 'distance']
scaled_features = XGame.copy()
features = scaled_features[numeric]
#scaler = ss.fit(features.values)
features = ss.transform(features.values)

scaled_features[numeric] = features

XGame = scaled_features

XGame = XGame.fillna(0)

XGame

model.evaluate(XGame, yGame)

from sklearn.metrics import classification_report

#predictions = model.predict(XGame)
Y_test = np.argmax(yGame, axis=1) # Convert one-hot to index
y_pred = model.predict_classes(XGame)
print(classification_report(Y_test, y_pred, target_names=['Rush', 'Pass'], digits=4))

game_predictions = model.predict_proba(XGame)

for i in range(len(yGame)):
  if np.argmax(yGame[i], axis=0) == np.argmax(game_predictions[i], axis=0):
    correct = "True"
  else:
    correct = "False"
  print("Predictions=%s, Actual=%s, Correct=%s" % (game_predictions[i], yGame[i], correct))