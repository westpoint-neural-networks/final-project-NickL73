{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conferenceNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3EYJ9u7555J",
        "colab_type": "text"
      },
      "source": [
        "# Ahead of the Game: Coaching Predictability in NCAA Football\n",
        "\n",
        "This notebook is Part II in a series that seeks to model the predictability of offenseive playcallers in the NCAA FBS football league. While this idea could be practically applied to any offensive playcaller in the game, we will use Lincoln Riley, the head coach of the Oklahoma Sooners, as a singular case study.\n",
        "\n",
        "In [Part I](https://colab.research.google.com/drive/1ITENEu7jQ-3Hox3Mxr-TRgueKHElmwCH#offline=true&sandboxMode=true), we used all of Lincoln Riley's called plays to try to predict his coaching behavior. In this notebook, we will explore whether or not Mr. Riley's behavior can be better predicted using a model of the aggregate coaching behavior in the Big XII.\n",
        "\n",
        "**NOTE: This notebook is meant to be used in [Google Colaboratory](https://colab.research.google.com). The instructions will assume as much, and may not be accurate if you're using a different platform.**\n",
        "\n",
        "We'll begin just as we did in Part I of the series, by importing the base modules necessary to start and setting a random seed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D1D1RlKcG4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "import random\n",
        "\n",
        "seed(485)\n",
        "random.seed(485)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apZ5EmTBvCxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DxYyhZ37bXr",
        "colab_type": "text"
      },
      "source": [
        "## Preparing our Data\n",
        "\n",
        "The data we will be using was again scraped from [collegefootballdata.com](https://www.collegefootballdata.com)\n",
        "\n",
        "Since Oklahoma is a member of the Big XII conference, our dataset will consist of every play that's been run by a Big XII team since Lincoln Riley started at Oklahoma in 2016. As such, it will be much larger than our previous data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF0wIatS78FK",
        "colab_type": "text"
      },
      "source": [
        "Again, we will need to import the data. To do this on Google Colab, you will first need to download the \"conferenceData.csv\" from the models folder in the [GitHub repository](https://github.com/westpoint-neural-networks/final-project-NickL73). Next, you will need to click on the folder icon on the toolbar to the left of Google Colab and upload the dataset.\n",
        "\n",
        "Once you have done that, load it into a Pandas dataframe and we'll inspect the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15OBpS2NwChs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "dba6888e-d9d7-429d-b3e3-c9eb2ffa8096"
      },
      "source": [
        "df = pd.read_csv('/content/conferenceData.csv')\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "      <th>play_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-14</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>1517</td>\n",
              "      <td>1517</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-17</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>1017</td>\n",
              "      <td>1017</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3600</td>\n",
              "      <td>1800</td>\n",
              "      <td>77</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2700</td>\n",
              "      <td>900</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3066</td>\n",
              "      <td>1266</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39853</th>\n",
              "      <td>-9</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>2070</td>\n",
              "      <td>270</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39854</th>\n",
              "      <td>28</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>502</td>\n",
              "      <td>502</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39855</th>\n",
              "      <td>-24</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>315</td>\n",
              "      <td>315</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39856</th>\n",
              "      <td>-7</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3476</td>\n",
              "      <td>1676</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39857</th>\n",
              "      <td>-3</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>2110</td>\n",
              "      <td>310</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>Rush</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39858 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       score_differential  oneScoreGame  period  ...  down  distance  play_type\n",
              "0                     -14         False       3  ...     1        10       Rush\n",
              "1                     -17         False       3  ...     1        10       Rush\n",
              "2                       0          True       1  ...     2        12       Rush\n",
              "3                       3          True       2  ...     1         6       Rush\n",
              "4                       0          True       1  ...     1        10       Rush\n",
              "...                   ...           ...     ...  ...   ...       ...        ...\n",
              "39853                  -9         False       2  ...     2         2       Rush\n",
              "39854                  28         False       4  ...     1         8       Rush\n",
              "39855                 -24         False       4  ...     3         0       Rush\n",
              "39856                  -7          True       1  ...     3         9       Rush\n",
              "39857                  -3          True       2  ...     1        10       Rush\n",
              "\n",
              "[39858 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0IAsqpIydnx",
        "colab_type": "text"
      },
      "source": [
        "Just as before, the data has been to clean certain features and engineer other features before use. Notice that with this dataset, we have about four times as many plays. This will hopefully make our model better, since it has more data to train on.\n",
        "\n",
        "\n",
        "Now that we have our data in a Pandas data frame, we have to prepare it for use in a neural network. The first step will be to formally define our target values (the play type) and input values (the scoreboard information) by [indexing](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html) our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahSpeEIvxjI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,0:8]\n",
        "y = df.iloc[:,8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm6-Sx1i96dM",
        "colab_type": "text"
      },
      "source": [
        "### Vectorizing the Data\n",
        "\n",
        "For use in a neural network, each piece of data must be interpretable by a machine. This means things like our values of \"True\" and \"False\", as well as our target values of \"Rush\" and \"Pass\", must be converted into some number. To do this, we will simply binarize the data.\n",
        "\n",
        "While we're at it, we'll go ahead and convert our target values into Keras categorical one-hot values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FlStfi06Ksg",
        "colab_type": "code",
        "outputId": "8eb4c836-5e2a-4296-90d9-4cfe7e867604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "X = X.replace({True:1, False:0})\n",
        "y = y.replace({'Rush':0, 'Pass':1})\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v9zyosv-WKd",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the Data\n",
        "\n",
        "Like in the coaching notebook, we'll split our dataset into training and validation sets using the scikit-learn [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function\n",
        "\n",
        "We will again use 85% of the data in the training set, and the remaining 15% of the data in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whLbGZQPyFg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYOArwPD3b5O",
        "colab_type": "text"
      },
      "source": [
        "###Scaling and Normalizing the Data\n",
        "\n",
        "Applying the sklearn [StandardScaler](https://stackoverflow.com/questions/38420847/apply-standardscaler-to-parts-of-a-data-set) to the features of our DataFrame seemed to work pretty well last time.We'll do that again, remembering to only by fit the StandardScaler to our **training data**. It's very important that we do not do this to the validation data at the same time, as that would cause data leakage in the model and decrease the overall accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pya78CZJMBB0",
        "colab_type": "code",
        "outputId": "12139cbe-dfa1-4af3-cd39-021ca65f157e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss = StandardScaler()\n",
        "numeric = ['score_differential', 'period', 'seconds_remaining', 'secondsInHalf', 'yardsToGoal', 'down', 'distance']\n",
        "scaled_features = X_train.copy()\n",
        "features = scaled_features[numeric]\n",
        "scaler = ss.fit(features.values)\n",
        "features = ss.transform(features.values)\n",
        "\n",
        "scaled_features[numeric] = features\n",
        "\n",
        "X_train = scaled_features\n",
        "X_train"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15772</th>\n",
              "      <td>-1.483643</td>\n",
              "      <td>0</td>\n",
              "      <td>0.431835</td>\n",
              "      <td>-0.447860</td>\n",
              "      <td>0.782926</td>\n",
              "      <td>-0.025787</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>1.624214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19083</th>\n",
              "      <td>0.872721</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.141220</td>\n",
              "      <td>0.556796</td>\n",
              "      <td>-1.303528</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.108681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29131</th>\n",
              "      <td>-0.675747</td>\n",
              "      <td>0</td>\n",
              "      <td>0.431835</td>\n",
              "      <td>-0.167043</td>\n",
              "      <td>1.318400</td>\n",
              "      <td>-1.344746</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18799</th>\n",
              "      <td>0.199474</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.017889</td>\n",
              "      <td>0.321622</td>\n",
              "      <td>-1.303528</td>\n",
              "      <td>1.463443</td>\n",
              "      <td>0.613858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20836</th>\n",
              "      <td>2.017240</td>\n",
              "      <td>0</td>\n",
              "      <td>0.431835</td>\n",
              "      <td>-0.117711</td>\n",
              "      <td>1.412470</td>\n",
              "      <td>-0.644049</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>-0.901675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22568</th>\n",
              "      <td>-0.069825</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.552009</td>\n",
              "      <td>1.340108</td>\n",
              "      <td>-1.221093</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35182</th>\n",
              "      <td>0.401448</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.456941</td>\n",
              "      <td>0.469537</td>\n",
              "      <td>-0.724000</td>\n",
              "      <td>0.015430</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17985</th>\n",
              "      <td>1.545968</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.456941</td>\n",
              "      <td>0.401231</td>\n",
              "      <td>-0.854251</td>\n",
              "      <td>1.375606</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>-1.483643</td>\n",
              "      <td>0</td>\n",
              "      <td>0.431835</td>\n",
              "      <td>-0.294170</td>\n",
              "      <td>1.075989</td>\n",
              "      <td>1.004649</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16880</th>\n",
              "      <td>-1.416318</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.456941</td>\n",
              "      <td>0.574844</td>\n",
              "      <td>-0.523197</td>\n",
              "      <td>0.798562</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33879 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       score_differential  oneScoreGame  ...      down  distance\n",
              "15772           -1.483643             0  ...  0.255795  1.624214\n",
              "19083            0.872721             0  ...  0.255795  0.108681\n",
              "29131           -0.675747             0  ... -0.951853  0.361270\n",
              "18799            0.199474             1  ...  1.463443  0.613858\n",
              "20836            2.017240             0  ...  0.255795 -0.901675\n",
              "...                   ...           ...  ...       ...       ...\n",
              "22568           -0.069825             1  ... -0.951853  0.361270\n",
              "35182            0.401448             1  ... -0.951853  0.361270\n",
              "17985            1.545968             0  ...  0.255795  0.361270\n",
              "174             -1.483643             0  ... -0.951853  0.361270\n",
              "16880           -1.416318             0  ... -0.951853  0.361270\n",
              "\n",
              "[33879 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtpUw_1n5MFH",
        "colab_type": "text"
      },
      "source": [
        "Now that we have instantiated a StandardScaler, we can transform all of the values in the **validation set** to the scale of the **training set**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIWYwqve5Loh",
        "colab_type": "code",
        "outputId": "9b237470-c4cc-462c-83b7-bd8e84f5745e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "scaled_features = X_validation.copy()\n",
        "features = scaled_features[numeric]\n",
        "features = ss.transform(features.values)\n",
        "\n",
        "scaled_features[numeric] = features\n",
        "\n",
        "X_validation = scaled_features\n",
        "X_validation"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25531</th>\n",
              "      <td>0.401448</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.493189</td>\n",
              "      <td>1.227948</td>\n",
              "      <td>-0.231875</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9432</th>\n",
              "      <td>0.603422</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.267398</td>\n",
              "      <td>0.797398</td>\n",
              "      <td>0.139083</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>-0.901675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17736</th>\n",
              "      <td>-0.069825</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.665854</td>\n",
              "      <td>1.557192</td>\n",
              "      <td>1.293171</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18738</th>\n",
              "      <td>0.401448</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.110862</td>\n",
              "      <td>0.498907</td>\n",
              "      <td>1.293171</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18991</th>\n",
              "      <td>0.872721</td>\n",
              "      <td>0</td>\n",
              "      <td>0.431835</td>\n",
              "      <td>-0.401373</td>\n",
              "      <td>0.871568</td>\n",
              "      <td>-1.179876</td>\n",
              "      <td>1.463443</td>\n",
              "      <td>-0.901675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22280</th>\n",
              "      <td>-0.069825</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.456941</td>\n",
              "      <td>0.515075</td>\n",
              "      <td>-0.637167</td>\n",
              "      <td>-0.561614</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22421</th>\n",
              "      <td>1.343994</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.456941</td>\n",
              "      <td>0.162157</td>\n",
              "      <td>-1.310127</td>\n",
              "      <td>-0.520397</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22031</th>\n",
              "      <td>-0.339123</td>\n",
              "      <td>1</td>\n",
              "      <td>1.320611</td>\n",
              "      <td>-1.055979</td>\n",
              "      <td>-0.376666</td>\n",
              "      <td>-0.850136</td>\n",
              "      <td>0.255795</td>\n",
              "      <td>-0.143908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21377</th>\n",
              "      <td>-0.069825</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.345717</td>\n",
              "      <td>1.164938</td>\n",
              "      <td>0.602022</td>\n",
              "      <td>1.210736</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30574</th>\n",
              "      <td>0.401448</td>\n",
              "      <td>1</td>\n",
              "      <td>1.320611</td>\n",
              "      <td>-0.903238</td>\n",
              "      <td>-0.085411</td>\n",
              "      <td>-0.850136</td>\n",
              "      <td>-0.951853</td>\n",
              "      <td>0.361270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5979 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       score_differential  oneScoreGame  ...      down  distance\n",
              "25531            0.401448             1  ...  0.255795  0.361270\n",
              "9432             0.603422             0  ...  0.255795 -0.901675\n",
              "17736           -0.069825             1  ... -0.951853  0.361270\n",
              "18738            0.401448             1  ... -0.951853  0.361270\n",
              "18991            0.872721             0  ...  1.463443 -0.901675\n",
              "...                   ...           ...  ...       ...       ...\n",
              "22280           -0.069825             1  ... -0.951853  0.361270\n",
              "22421            1.343994             0  ... -0.951853  0.361270\n",
              "22031           -0.339123             1  ...  0.255795 -0.143908\n",
              "21377           -0.069825             1  ... -0.951853  0.361270\n",
              "30574            0.401448             1  ... -0.951853  0.361270\n",
              "\n",
              "[5979 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruekv4Q0__AB",
        "colab_type": "text"
      },
      "source": [
        "##Building a Model\n",
        "\n",
        "So far, we have seen very little difference between the process in this notebook and the process in Part I. Now, however, we will see a major departure from the coaching model we previously created. This network will have a significantly different architecture and thought process behind it, which will hopefully increase our accuracy even more.\n",
        "\n",
        "**NOTE: Remember that is not a model of Lincoln Riley. Rather, it will be a model of the entire Big XII conference, that we will apply to Lincoln Riley. This is a subtle, but important distinction to make. Even though we might get a high level of predictability for the conference, we still might see low predictability in Lincoln Riley.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGCnyUhcA-zt",
        "colab_type": "text"
      },
      "source": [
        "###Model Architecture\n",
        "\n",
        "Our conference model will be made up of six different layers. Like in the coaching model, we will primarily use Densely connected layers with an **elu** activation function. Notice however, that these Dense layers are separated by a layer of BatchNormalization, which recenters and rescales the input to the next layer. This should help increase the accuracy of our model. Additionally. we specify a lower rate of Dropout.\n",
        "\n",
        "We will again use a **sigmoid** activation in the final layer and **binary_crossentropy** as our loss function, given that this is still a binary classificaton problem.\n",
        "\n",
        "Lastly, we will specify a learning rate for **Adam**, our optimizer. We're doing this because we will ultimately use a learning rate reduction callback while training this model. As such, we need to start with a high learning rate so that we have room to decrease it while training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IuJWx7x00fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models, layers, optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='elu', input_dim=8))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(16, activation='elu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(2, activation='sigmoid'))\n",
        "\n",
        "ad = optimizers.Adam(learning_rate=0.1)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNSd88tWCF-s",
        "colab_type": "text"
      },
      "source": [
        "###Training the Model\n",
        "\n",
        "With a model defined and compiled, we're ready to begin training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYjAeUIxCWk9",
        "colab_type": "text"
      },
      "source": [
        "Before we do so, however, let's write a couple of callbacks that might help us achieve the best model possible.\n",
        "\n",
        "The first callback we will use will be **EarlyStopping**, which monitors the training progress. If the validation scores stop improving for a certain number of epochs, it will stop the training and restore the weights of the best model we saw during training. This is useful because it allows us to set an arbitrarily high number of epochs for training, without having to worry about getting just the right number of epochs for our model.\n",
        "\n",
        "Second, we will use **ReduceLROnPlateau**, which reduces our learning rate if the validation loss of our model seems to stall out. This will make our training in the beginning go a little bit faster, but will slow it down as we get closer and closer to a finely tuned model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTmRdxxFR1qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# early stopping if training for more epochs\n",
        "es_cb = EarlyStopping(monitor = 'val_loss', verbose=1, patience = 25, restore_best_weights=True)\n",
        "\n",
        "#reduce learning rate on plateau\n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)\n",
        "\n",
        "cb_list = [es_cb, rlr_cb]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzFNXLomDSeo",
        "colab_type": "text"
      },
      "source": [
        "With these callbacks defined, we're ready to begin training our model while remembering to set a high number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0_trt8e1OgC",
        "colab_type": "code",
        "outputId": "6e69fccb-70e5-49aa-c856-6b9ee50797ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history2 = model.fit(X_train, y_train,batch_size=24, epochs=1000, validation_data=(X_validation, y_validation), callbacks=cb_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6657 - accuracy: 0.6034 - val_loss: 0.6454 - val_accuracy: 0.6284 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6488 - accuracy: 0.6200 - val_loss: 0.6400 - val_accuracy: 0.6392 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6453 - accuracy: 0.6207 - val_loss: 0.6392 - val_accuracy: 0.6369 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6438 - accuracy: 0.6237 - val_loss: 0.6397 - val_accuracy: 0.6351 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6431 - accuracy: 0.6245 - val_loss: 0.6381 - val_accuracy: 0.6377 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6422 - accuracy: 0.6265 - val_loss: 0.6362 - val_accuracy: 0.6407 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6410 - accuracy: 0.6266 - val_loss: 0.6368 - val_accuracy: 0.6401 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6403 - accuracy: 0.6300 - val_loss: 0.6374 - val_accuracy: 0.6394 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6399 - accuracy: 0.6319 - val_loss: 0.6368 - val_accuracy: 0.6406 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6399 - accuracy: 0.6293 - val_loss: 0.6358 - val_accuracy: 0.6391 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6387 - accuracy: 0.6308 - val_loss: 0.6373 - val_accuracy: 0.6352 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6384 - accuracy: 0.6298 - val_loss: 0.6361 - val_accuracy: 0.6397 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6380 - accuracy: 0.6307 - val_loss: 0.6357 - val_accuracy: 0.6406 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6369 - accuracy: 0.6322 - val_loss: 0.6340 - val_accuracy: 0.6411 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6365 - accuracy: 0.6323 - val_loss: 0.6326 - val_accuracy: 0.6399 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6354 - accuracy: 0.6320 - val_loss: 0.6351 - val_accuracy: 0.6387 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6366 - accuracy: 0.6320 - val_loss: 0.6325 - val_accuracy: 0.6417 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6337 - accuracy: 0.6364 - val_loss: 0.6318 - val_accuracy: 0.6387 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6340 - accuracy: 0.6335 - val_loss: 0.6319 - val_accuracy: 0.6402 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6340 - accuracy: 0.6363 - val_loss: 0.6306 - val_accuracy: 0.6429 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6343 - accuracy: 0.6336 - val_loss: 0.6313 - val_accuracy: 0.6386 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6338 - accuracy: 0.6325 - val_loss: 0.6322 - val_accuracy: 0.6453 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6337 - accuracy: 0.6341 - val_loss: 0.6301 - val_accuracy: 0.6416 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6323 - accuracy: 0.6365 - val_loss: 0.6302 - val_accuracy: 0.6446 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6328 - accuracy: 0.6350 - val_loss: 0.6295 - val_accuracy: 0.6412 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6330 - accuracy: 0.6353 - val_loss: 0.6295 - val_accuracy: 0.6433 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6314 - accuracy: 0.6370 - val_loss: 0.6286 - val_accuracy: 0.6458 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6310 - accuracy: 0.6388 - val_loss: 0.6286 - val_accuracy: 0.6397 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6317 - accuracy: 0.6381 - val_loss: 0.6278 - val_accuracy: 0.6409 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6309 - accuracy: 0.6377 - val_loss: 0.6281 - val_accuracy: 0.6404 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6309 - accuracy: 0.6380 - val_loss: 0.6281 - val_accuracy: 0.6392 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6307 - accuracy: 0.6356 - val_loss: 0.6271 - val_accuracy: 0.6416 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6298 - accuracy: 0.6391 - val_loss: 0.6255 - val_accuracy: 0.6417 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6303 - accuracy: 0.6368 - val_loss: 0.6270 - val_accuracy: 0.6436 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6299 - accuracy: 0.6376 - val_loss: 0.6253 - val_accuracy: 0.6439 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6289 - accuracy: 0.6380 - val_loss: 0.6265 - val_accuracy: 0.6417 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6291 - accuracy: 0.6380 - val_loss: 0.6249 - val_accuracy: 0.6409 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6282 - accuracy: 0.6414 - val_loss: 0.6261 - val_accuracy: 0.6377 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6298 - accuracy: 0.6381 - val_loss: 0.6266 - val_accuracy: 0.6441 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6276 - accuracy: 0.6374 - val_loss: 0.6247 - val_accuracy: 0.6416 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6284 - accuracy: 0.6381 - val_loss: 0.6258 - val_accuracy: 0.6401 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6272 - accuracy: 0.6391 - val_loss: 0.6247 - val_accuracy: 0.6351 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6286 - accuracy: 0.6395 - val_loss: 0.6248 - val_accuracy: 0.6407 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6285 - accuracy: 0.6401 - val_loss: 0.6262 - val_accuracy: 0.6427 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6270 - accuracy: 0.6403 - val_loss: 0.6252 - val_accuracy: 0.6391 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6262 - accuracy: 0.6420 - val_loss: 0.6242 - val_accuracy: 0.6427 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6257 - accuracy: 0.6443 - val_loss: 0.6253 - val_accuracy: 0.6416 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6261 - accuracy: 0.6387 - val_loss: 0.6249 - val_accuracy: 0.6412 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6271 - accuracy: 0.6426 - val_loss: 0.6263 - val_accuracy: 0.6391 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6274 - accuracy: 0.6405 - val_loss: 0.6251 - val_accuracy: 0.6417 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "1412/1412 [==============================] - 3s 2ms/step - loss: 0.6262 - accuracy: 0.6390 - val_loss: 0.6241 - val_accuracy: 0.6426 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6269 - accuracy: 0.6400 - val_loss: 0.6249 - val_accuracy: 0.6426 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6264 - accuracy: 0.6405 - val_loss: 0.6242 - val_accuracy: 0.6431 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6259 - accuracy: 0.6420 - val_loss: 0.6243 - val_accuracy: 0.6433 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6244 - accuracy: 0.6420 - val_loss: 0.6258 - val_accuracy: 0.6426 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6258 - accuracy: 0.6421 - val_loss: 0.6249 - val_accuracy: 0.6407 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6241 - accuracy: 0.6409 - val_loss: 0.6236 - val_accuracy: 0.6439 - lr: 1.0000e-04\n",
            "Epoch 58/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6248 - accuracy: 0.6400 - val_loss: 0.6237 - val_accuracy: 0.6427 - lr: 1.0000e-04\n",
            "Epoch 59/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6249 - accuracy: 0.6433 - val_loss: 0.6235 - val_accuracy: 0.6439 - lr: 1.0000e-04\n",
            "Epoch 60/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6246 - accuracy: 0.6413 - val_loss: 0.6235 - val_accuracy: 0.6416 - lr: 1.0000e-04\n",
            "Epoch 61/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6238 - accuracy: 0.6435 - val_loss: 0.6233 - val_accuracy: 0.6417 - lr: 1.0000e-04\n",
            "Epoch 62/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6240 - accuracy: 0.6422 - val_loss: 0.6233 - val_accuracy: 0.6443 - lr: 1.0000e-04\n",
            "Epoch 63/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6242 - accuracy: 0.6441 - val_loss: 0.6233 - val_accuracy: 0.6422 - lr: 1.0000e-04\n",
            "Epoch 64/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6240 - accuracy: 0.6447 - val_loss: 0.6233 - val_accuracy: 0.6438 - lr: 1.0000e-04\n",
            "Epoch 65/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6239 - accuracy: 0.6439 - val_loss: 0.6235 - val_accuracy: 0.6431 - lr: 1.0000e-04\n",
            "Epoch 66/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6248 - accuracy: 0.6441 - val_loss: 0.6235 - val_accuracy: 0.6438 - lr: 1.0000e-04\n",
            "Epoch 67/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6239 - accuracy: 0.6441 - val_loss: 0.6232 - val_accuracy: 0.6441 - lr: 1.0000e-04\n",
            "Epoch 68/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6232 - accuracy: 0.6441 - val_loss: 0.6234 - val_accuracy: 0.6444 - lr: 1.0000e-04\n",
            "Epoch 69/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6249 - accuracy: 0.6400 - val_loss: 0.6234 - val_accuracy: 0.6458 - lr: 1.0000e-04\n",
            "Epoch 70/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6241 - accuracy: 0.6427 - val_loss: 0.6233 - val_accuracy: 0.6441 - lr: 1.0000e-04\n",
            "Epoch 71/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6254 - accuracy: 0.6402 - val_loss: 0.6230 - val_accuracy: 0.6441 - lr: 1.0000e-04\n",
            "Epoch 72/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6246 - accuracy: 0.6422 - val_loss: 0.6231 - val_accuracy: 0.6451 - lr: 1.0000e-04\n",
            "Epoch 73/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6251 - accuracy: 0.6435 - val_loss: 0.6234 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
            "Epoch 74/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6242 - accuracy: 0.6435 - val_loss: 0.6231 - val_accuracy: 0.6453 - lr: 1.0000e-04\n",
            "Epoch 75/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6228 - accuracy: 0.6463 - val_loss: 0.6233 - val_accuracy: 0.6436 - lr: 1.0000e-04\n",
            "Epoch 76/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6242 - accuracy: 0.6418 - val_loss: 0.6230 - val_accuracy: 0.6448 - lr: 1.0000e-04\n",
            "Epoch 77/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6233 - accuracy: 0.6435 - val_loss: 0.6233 - val_accuracy: 0.6441 - lr: 1.0000e-04\n",
            "Epoch 78/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6238 - accuracy: 0.6427 - val_loss: 0.6232 - val_accuracy: 0.6439 - lr: 1.0000e-04\n",
            "Epoch 79/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6237 - accuracy: 0.6439 - val_loss: 0.6232 - val_accuracy: 0.6444 - lr: 1.0000e-04\n",
            "Epoch 80/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6236 - accuracy: 0.6443 - val_loss: 0.6234 - val_accuracy: 0.6427 - lr: 1.0000e-04\n",
            "Epoch 81/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6251 - accuracy: 0.6402 - val_loss: 0.6233 - val_accuracy: 0.6443 - lr: 1.0000e-04\n",
            "Epoch 82/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6241 - accuracy: 0.6425 - val_loss: 0.6232 - val_accuracy: 0.6443 - lr: 1.0000e-05\n",
            "Epoch 83/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6259 - accuracy: 0.6419 - val_loss: 0.6233 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
            "Epoch 84/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6239 - accuracy: 0.6411 - val_loss: 0.6232 - val_accuracy: 0.6453 - lr: 1.0000e-05\n",
            "Epoch 85/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6243 - accuracy: 0.6405 - val_loss: 0.6232 - val_accuracy: 0.6448 - lr: 1.0000e-05\n",
            "Epoch 86/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6230 - accuracy: 0.6459 - val_loss: 0.6233 - val_accuracy: 0.6414 - lr: 1.0000e-05\n",
            "Epoch 87/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6248 - accuracy: 0.6430 - val_loss: 0.6233 - val_accuracy: 0.6424 - lr: 1.0000e-05\n",
            "Epoch 88/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6231 - accuracy: 0.6424 - val_loss: 0.6231 - val_accuracy: 0.6444 - lr: 1.0000e-05\n",
            "Epoch 89/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6241 - accuracy: 0.6405 - val_loss: 0.6231 - val_accuracy: 0.6459 - lr: 1.0000e-05\n",
            "Epoch 90/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6246 - accuracy: 0.6446 - val_loss: 0.6231 - val_accuracy: 0.6448 - lr: 1.0000e-05\n",
            "Epoch 91/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6218 - accuracy: 0.6453 - val_loss: 0.6231 - val_accuracy: 0.6461 - lr: 1.0000e-05\n",
            "Epoch 92/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6227 - accuracy: 0.6440 - val_loss: 0.6232 - val_accuracy: 0.6431 - lr: 1.0000e-06\n",
            "Epoch 93/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6248 - accuracy: 0.6417 - val_loss: 0.6232 - val_accuracy: 0.6453 - lr: 1.0000e-06\n",
            "Epoch 94/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6246 - accuracy: 0.6422 - val_loss: 0.6232 - val_accuracy: 0.6441 - lr: 1.0000e-06\n",
            "Epoch 95/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6224 - accuracy: 0.6450 - val_loss: 0.6231 - val_accuracy: 0.6453 - lr: 1.0000e-06\n",
            "Epoch 96/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6231 - accuracy: 0.6431 - val_loss: 0.6233 - val_accuracy: 0.6434 - lr: 1.0000e-06\n",
            "Epoch 97/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6226 - accuracy: 0.6441 - val_loss: 0.6232 - val_accuracy: 0.6444 - lr: 1.0000e-06\n",
            "Epoch 98/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6242 - accuracy: 0.6420 - val_loss: 0.6231 - val_accuracy: 0.6451 - lr: 1.0000e-06\n",
            "Epoch 99/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6226 - accuracy: 0.6431 - val_loss: 0.6232 - val_accuracy: 0.6441 - lr: 1.0000e-06\n",
            "Epoch 100/1000\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6231 - accuracy: 0.6455 - val_loss: 0.6231 - val_accuracy: 0.6446 - lr: 1.0000e-06\n",
            "Epoch 101/1000\n",
            "1383/1412 [============================>.] - ETA: 0s - loss: 0.6232 - accuracy: 0.6450Restoring model weights from the end of the best epoch.\n",
            "1412/1412 [==============================] - 2s 2ms/step - loss: 0.6234 - accuracy: 0.6447 - val_loss: 0.6231 - val_accuracy: 0.6461 - lr: 1.0000e-06\n",
            "Epoch 00101: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1xT9-5Qo3vY",
        "colab_type": "text"
      },
      "source": [
        "If you look at the training history closely, you'll notice that as the validation loss begins to plateau, we automatically reduce the learning rate. Eventually it, and the validation accuracy, plateau and the model stops training. Once it does, it restores the weights of the model after the epoch with lowest validation loss.\n",
        "\n",
        "Now let's take a look at the model's performance in terms of accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Luk9tRA1jHU",
        "colab_type": "code",
        "outputId": "d8148f60-5459-47f6-fa70-b6d654e9254b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history2.history['accuracy'])\n",
        "plt.plot(history2.history['val_accuracy'])\n",
        "plt.title('Training v. Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_gn9ncopepG",
        "colab_type": "text"
      },
      "source": [
        "Interestingly, we see evidence of underfitting at the beginning of training but both training and validation accuracies converge around epoch 100. Our restored validation accuracy appears to be 64.61%. This is pretty similar to the coaching model, which might suggest that the Big XII is just about as predictable as Lincoln Riley.\n",
        "\n",
        "Let's take a look at the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFSt2bSO1pDB",
        "colab_type": "code",
        "outputId": "50da4f71-4ccd-41d7-aa8f-ae6d2eab3e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('Training v. Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsZwhdeip9YY",
        "colab_type": "text"
      },
      "source": [
        "This time, we see a much more gradual convergence of the training and validation losses. This looks pretty good, and they track each other well. Now, we're ready to save and test the model.\n",
        "\n",
        "**NOTE: The next block of code will save the model to the same content folder as our dataset in the Colab runtime. If you want to keep the model, be sure to right click and download it from the Colab directory.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJGC17WIqb01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('conferenceModel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAvnIygMqHrG",
        "colab_type": "text"
      },
      "source": [
        "##Testing the Model\n",
        "\n",
        "As we discussed earlier, we built a model of the Big XII conference. This model describes the aggregate predictability of the conference as a whole, but we're going to use it to see if it reveals anything when applied soley to Lincoln Riley.\n",
        "\n",
        "Again, we're using the 2019 Big XII Championship Game between Oklahoma and Baylor as our test case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyFGshafq27n",
        "colab_type": "text"
      },
      "source": [
        "Obviously, we'll start by reading in our test data and manipulating it for use in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeQHv9Oy8RHJ",
        "colab_type": "code",
        "outputId": "b23c9079-59d5-4c04-8acf-d173ec487b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "testDF = pd.read_csv('/content/test.csv')\n",
        "XGame = testDF.iloc[:,0:8]\n",
        "yGame= testDF.iloc[:,8]\n",
        "\n",
        "XGame = XGame.replace({True:1, False:0})\n",
        "yGame = yGame.replace({'Rush':0, 'Pass':1, 'FG':2, 'Punt':3})\n",
        "yGame = to_categorical(yGame)\n",
        "\n",
        "scaled_features = XGame.copy()\n",
        "features = scaled_features[numeric]\n",
        "features = ss.transform(features.values)\n",
        "\n",
        "scaled_features[numeric] = features\n",
        "\n",
        "XGame = scaled_features\n",
        "XGame"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score_differential</th>\n",
              "      <th>oneScoreGame</th>\n",
              "      <th>period</th>\n",
              "      <th>seconds_remaining</th>\n",
              "      <th>secondsInHalf</th>\n",
              "      <th>yardsToGoal</th>\n",
              "      <th>down</th>\n",
              "      <th>distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3595</td>\n",
              "      <td>1795</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3554</td>\n",
              "      <td>1754</td>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3522</td>\n",
              "      <td>1722</td>\n",
              "      <td>70</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3337</td>\n",
              "      <td>1537</td>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3299</td>\n",
              "      <td>1499</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "      <td>119</td>\n",
              "      <td>119</td>\n",
              "      <td>52</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>47</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "      <td>-900</td>\n",
              "      <td>-900</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "      <td>-900</td>\n",
              "      <td>-900</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "      <td>-900</td>\n",
              "      <td>-900</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    score_differential  oneScoreGame  period  ...  yardsToGoal  down  distance\n",
              "0                    0          True       1  ...           75     1        10\n",
              "1                    0          True       1  ...           72     2         7\n",
              "2                    0          True       1  ...           70     3         5\n",
              "3                    0          True       1  ...           78     1        10\n",
              "4                    0          True       1  ...            7     1         7\n",
              "..                 ...           ...     ...  ...          ...   ...       ...\n",
              "69                   0          True       4  ...           52     2         8\n",
              "70                   0          True       4  ...           47     3         3\n",
              "71                   0          True       5  ...           23     1        10\n",
              "72                   0          True       5  ...           11     1        10\n",
              "73                   7          True       5  ...            5     2         4\n",
              "\n",
              "[74 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBtuzudgrMqd",
        "colab_type": "text"
      },
      "source": [
        "###Evaluating Performance\n",
        "\n",
        "Now that the data has been prepared, let's see how well our conference model can predict Lincoln Riley."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9d35ab8f-c8db-4841-a1ea-08321aa32bc8",
        "id": "SZTrB8kI_z51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model.evaluate(XGame, yGame)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6378172636032104, 0.6351351141929626]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv6jcyl3rfac",
        "colab_type": "text"
      },
      "source": [
        "Wow, this is a pretty high accuracy given that our final validation accuracy was about 64%. It's also a bit surprising that this model was about 4% more accurate than our coaching model. This suggests that using a model of the Big XII Conference might actually be a better predictor of Lincoln Riley's play calling.\n",
        "\n",
        "Let's take a deeper look into the performance using sklearn's **classification report**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ZuI8twA2VA",
        "colab_type": "code",
        "outputId": "f76d7e4e-0b53-47b5-914e-7147a1f2a1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "Y_test = np.argmax(yGame, axis=1) # Convert one-hot to index\n",
        "y_pred = np.argmax(model.predict(XGame), axis=1)\n",
        "print(classification_report(Y_test, y_pred, target_names=['Rush', 'Pass'], digits=5))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Rush    0.73810   0.65957   0.69663        47\n",
            "        Pass    0.50000   0.59259   0.54237        27\n",
            "\n",
            "    accuracy                        0.63514        74\n",
            "   macro avg    0.61905   0.62608   0.61950        74\n",
            "weighted avg    0.65122   0.63514   0.64035        74\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqm5xAaSs9gp",
        "colab_type": "text"
      },
      "source": [
        "According to the classification report, we see similar behavior to that of the coaching model. Though to a lesser degree, we are still guessing pass more than rush. However, this seems to be a much more balanced and accurate model on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sHnxvnGtXBc",
        "colab_type": "text"
      },
      "source": [
        "##Conclusion\n",
        "\n",
        "This notebook explored the utility of applying a play prediction model based off of the Big XII NCAA football conference to a game of plays called by Lincoln Riley, the head coach of the Oklahoma Sooners. Surprisingly, it did a better job of predicting his behavior than a model based soley on his own history of play calling.\n",
        "\n",
        "https://colab.research.google.com/drive/1gG2g3m8M6z9hshwrL4Jj_VSWoGZn3zDL\n",
        "Can we get even better? What would be the result of modeling the coaching behavior of the entire NCAA FBS league and applying it to Lincoln Riley? We'll find out in [Part III](https://colab.research.google.com/drive/1gG2g3m8M6z9hshwrL4Jj_VSWoGZn3zDL#offline=true&sandboxMode=true) of this series."
      ]
    }
  ]
}